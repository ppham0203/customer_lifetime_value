{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.10"
    },
    "analyzedDataset": "last_year_join",
    "creator": "admin",
    "createdOn": 1651174325488,
    "tags": [],
    "customFields": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Statistical analysis (Single Population) on last_year_join"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Univariate analysis is perhaps the simplest form of statistical analysis. The key fact is that only one variable is involved.\n",
        "\n",
        "Bivariate analysis involves the analysis of two variables (often denoted as X, Y), for the purpose of determining the empirical relationship between them.\n",
        "\n",
        "\u003ccenter\u003e**For bivariate analysis please use the Statistical analysis (Multiple Populations) variant of this notebook.**\u003c/center\u003e\n",
        "\n",
        "* [Setup and loading the data](#setup)\n",
        "* [Preprocessing of the data](#preprocessing)\n",
        "* [Statistical analysis and vizualisation](#general)\n",
        "* [Single population tests](#tests_single)\n",
        "\n",
        "\u003ccenter\u003e\u003cstrong\u003eSelect Cell \u003e Run All to execute the whole analysis\u003c/strong\u003e\u003c/center\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and dataset loading \u003ca id\u003d\"setup\" /\u003e \n",
        "\n",
        "First of all, let\u0027s load the libraries that we\u0027ll use"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "%pylab inline"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "import dataiku                               # Access to Dataiku datasets\n",
        "import pandas as pd, numpy as np             # Data manipulation \n",
        "from matplotlib import pyplot as plt         # Graphing\n",
        "import seaborn as sns                        # Graphing\n",
        "#sns.set(style\u003d\"white\")                       # Tuning the style of charts\n",
        "import warnings                              # Disable some warnings\n",
        "warnings.filterwarnings(\"ignore\",category\u003dDeprecationWarning)\n",
        "from scipy import stats                      # Stats"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first thing we do is now to load the dataset and put aside the three main types of columns:\n",
        "\n",
        "* Numerics\n",
        "* Categorical\n",
        "* Dates\n",
        "\n",
        "Statistical analysis requires having the data in memory, we are only going to load a sample of the data. Modify the following cell to change the size of the sample."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "dataset_limit \u003d 10000"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load a DSS dataset as a Pandas dataframe"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Take a handle on the dataset\n",
        "mydataset \u003d dataiku.Dataset(\"last_year_join\")\n",
        "\n",
        "# Load the first lines.\n",
        "# You can also load random samples, limit yourself to some columns, or only load\n",
        "# data matching some filters.\n",
        "#\n",
        "# Please refer to the Dataiku Python API documentation for more information\n",
        "df \u003d mydataset.get_dataframe(limit \u003d dataset_limit)\n",
        "\n",
        "df_orig \u003d df.copy()\n",
        "\n",
        "# Get the column names\n",
        "numerical_columns \u003d list(df.select_dtypes(include\u003d[np.number]).columns)\n",
        "categorical_columns \u003d list(df.select_dtypes(include\u003d[object]).columns)\n",
        "date_columns \u003d list(df.select_dtypes(include\u003d[\u0027\u003cM8[ns]\u0027]).columns)\n",
        "\n",
        "# Print a quick summary of what we just loaded\n",
        "print(\"Loaded dataset\")\n",
        "print(\"   Rows: %s\" % df.shape[0])\n",
        "print(\"   Columns: %s (%s num, %s cat, %s date)\" % (df.shape[1], \n",
        "                                                    len(numerical_columns), len(categorical_columns),\n",
        "                                                    len(date_columns)))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing of the data \u003ca id\u003d\"preprocessing\" /\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will assume that the values are in the first numerical column."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "value_col \u003d numerical_columns[0]"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uncomment the following lines to take control on this"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "#value_col \u003d u\u0027my_value_column\u0027\n",
        "print(\"Selected value column is \u0027%s\u0027\" % (value_col))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We impute missing values in the value column"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Use mean for numerical features\n",
        "v \u003d df[value_col].mean()\n",
        "if np.isnan(v):\n",
        "    v \u003d 0\n",
        "print(\"Filling value column \u0027%s\u0027 with %s\" % (value_col, v))\n",
        "df[value_col] \u003d df[value_col].fillna(v)\n",
        "df_pop_1 \u003d df[value_col]"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical analysis and vizualisation \u003ca id\u003d\"general\" /a\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### General statistics\n",
        "Number of records, mean, standard deviation, minimal value, quartiles, maximum value, mode, variance, skewness and kurtosis."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "additional_stats \u003d [\"var\", \"skew\", \"kurtosis\"]\n",
        "print(\"Stats about your series:\\n\", df_pop_1.describe().append(pd.Series(NaN if df_pop_1.mode().empty else df_pop_1.mode()[0], index\u003d[\"mode\"])).append(pd.Series([df_pop_1.__getattr__(x)() for x in additional_stats], index\u003dadditional_stats)))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Histogram\n",
        "Histograms let you see the number of occurrences in your value column."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "plt.title(\"Histogram of \"+value_col);\n",
        "plt.hist(df_pop_1);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Distplot\n",
        "Distplots combine an histogram with a kernel density estimation."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "sns.distplot(df_pop_1);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Box plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple way of representing statistical data on a plot in which a rectangle is drawn to represent the second and third quartiles, with a vertical line inside to indicate the median value. The lower and upper quartiles are shown as horizontal lines either side of the rectangle."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "sns.boxplot(df_pop_1);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Violin plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The violin plot is similar to box plots, except that they also show the probability density of the data at different values. Violin plots include a marker for the median of the data and a box indicating the interquartile range, as in standard box plots. Overlaid on this box plot is a kernel density estimation. "
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "sns.violinplot(df_pop_1);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Letter value plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Letter value plots are an improvement upon boxplots for large datasets.\n",
        "\n",
        "They display the median and the quartiles, like a standard box plot, but will also draw boxes for subsequent \"eights\", \"sixteenth\" etc... which are generically called letter values.\n",
        "\n",
        "A cut off condition will leave a reasonable number of outliers out of the final boxes, helping you spot them easily.\n",
        "\n",
        "Letter value plots give a good sense of the distribution of data, and of its skewness."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "sns.lvplot(df_pop_1);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical testing \u003ca id\u003d\"tests\" /a\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reminder:** For a given significance level (e.g. 0.05), if the resulting p-value is smaller (p \u003c 0.05), the null hypothesis is rejected. Otherwise (p ≥ 0.05) it cannot be rejected."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "# Define your confidence threshold here, default is 0.05\n",
        "confidence \u003d 0.05"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "def analyse_results(confidence, pvalue, message, population_name\u003d\"your series\"):\n",
        "    if pvalue \u003c confidence:\n",
        "        print(\"The hypothesis of \" + message + \" for \"+ population_name + \" is rejected with pvalue %s (smaller than %s)\" % (pvalue, confidence))\n",
        "    else:\n",
        "        print(\"The hypothesis of \" + message + \" for \"+ population_name + \" can not be rejected, pvalue was %s (greater than %s)\" % (pvalue, confidence))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Single population tests \u003ca id\u003d\"tests_single\" /a\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Goodness of fit with a normal law: Shapiro-Wilk test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The null-hypothesis of this test is that the population is normally distributed."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "pvalue_1 \u003d stats.shapiro(df_pop_1)[1]\n",
        "test \u003d \u0027normal distribution\u0027\n",
        "analyse_results(confidence, pvalue_1, test)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test for the average value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The null-hypothesis of this test is that the population has the specified mean."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "# Define the mean you ant to test for here\n",
        "tested_mean \u003d 0"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "pvalue_1 \u003d stats.ttest_1samp(df_pop_1, tested_mean).pvalue\n",
        "test \u003d \u0027mean\u003d%s\u0027 % (tested_mean)\n",
        "analyse_results(confidence, pvalue_1, test)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u003ccenter\u003e**If you have multiple populations and want to run bivariate analyses please use the Statistical analysis (Multiple Populations) variant of this notebook.**\u003c/center\u003e"
      ]
    }
  ]
}